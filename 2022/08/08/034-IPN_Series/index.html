<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>图像投影网络（Image Projection Network, IPN）系列论文阅读笔记 | “干杯( ﾟ-ﾟ)っロ”</title><meta name="author" content="SvyJ"><meta name="copyright" content="SvyJ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="主要是以下两篇论文：IPN（TMI 2020）：Image Projection Network: 3D to 2D Image Segmentation in OCTA ImagesIPN V2（arXiv 2020）：IPN-V2 and OCTA-500: Methodology and Dataset for Retinal Image Segmentation    图像投影网络的设计来">
<meta property="og:type" content="article">
<meta property="og:title" content="图像投影网络（Image Projection Network, IPN）系列论文阅读笔记">
<meta property="og:url" content="http://example.com/2022/08/08/034-IPN_Series/index.html">
<meta property="og:site_name" content="“干杯( ﾟ-ﾟ)っロ”">
<meta property="og:description" content="主要是以下两篇论文：IPN（TMI 2020）：Image Projection Network: 3D to 2D Image Segmentation in OCTA ImagesIPN V2（arXiv 2020）：IPN-V2 and OCTA-500: Methodology and Dataset for Retinal Image Segmentation    图像投影网络的设计来">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2022/08/08/jJFpZ8Wo1TECk3P.png">
<meta property="article:published_time" content="2022-08-08T13:56:48.000Z">
<meta property="article:modified_time" content="2022-08-08T13:56:48.000Z">
<meta property="article:author" content="SvyJ">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="网络模型">
<meta property="article:tag" content="图像分割">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2022/08/08/jJFpZ8Wo1TECk3P.png"><link rel="shortcut icon" href="/images/logo.png"><link rel="canonical" href="http://example.com/2022/08/08/034-IPN_Series/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: SvyJ","link":"链接: ","source":"来源: “干杯( ﾟ-ﾟ)っロ”","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '图像投影网络（Image Projection Network, IPN）系列论文阅读笔记',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-08-08 21:56:48'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="//at.alicdn.com/t/font_3054216_qov50ieeupn.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (false) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2023/07/24/PEyfxB56HsbACYo.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">31</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2022/08/08/jJFpZ8Wo1TECk3P.png')"><nav id="nav"><span id="blog-info"><a href="/" title="“干杯( ﾟ-ﾟ)っロ”"><img class="site-icon" src="/images/logo.png"/><span class="site-name">“干杯( ﾟ-ﾟ)っロ”</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">图像投影网络（Image Projection Network, IPN）系列论文阅读笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-08T13:56:48.000Z" title="发表于 2022-08-08 21:56:48">2022-08-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-08T13:56:48.000Z" title="更新于 2022-08-08 21:56:48">2022-08-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">1.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>7分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="图像投影网络（Image Projection Network, IPN）系列论文阅读笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>主要是以下两篇论文：<br>IPN（<strong>TMI 2020</strong>）：Image Projection Network: 3D to 2D Image Segmentation in OCTA Images<br>IPN V2（<strong>arXiv 2020</strong>）：IPN-V2 and OCTA-500: Methodology and Dataset for Retinal Image Segmentation</p>
<!-- PAENet（**BIBM 2021**）：PAENet: A Progressive Attention-Enhanced Network for 3D to 2D Retinal Vessel Segmentation -->

<hr>
<h2 id="图像投影网络的设计来源"><a href="#图像投影网络的设计来源" class="headerlink" title="图像投影网络的设计来源"></a>图像投影网络的设计来源</h2><h3 id="眼科临床"><a href="#眼科临床" class="headerlink" title="眼科临床"></a>眼科临床</h3><blockquote>
<p>“Comparing to color fundus imaging technology, OCT can acquire more detailed information about retinal structures and thus becomes a leading modality in the clinic observation of retinopathy.” <strong>与彩色眼底成像技术相比，OCT可以获取更详细的视网膜结构信息，成为视网膜病变临床观察的主要方式。</strong></p>
</blockquote>
<p><img src="https://s2.loli.net/2022/08/08/9pKf7yDr5ogiFa3.png"></p>
<h3 id="诊疗指标"><a href="#诊疗指标" class="headerlink" title="诊疗指标"></a>诊疗指标</h3><blockquote>
<p>“Both OCT and OCTA can provide 3D data, but most retinal indicators, such as the vessel density and the FAZ area, are quantified on the projection maps rather than 3D space.” <strong>OCT 和 OCTA 都可以提供 3D 数据，但大多数视网膜指标，例如血管密度和 FAZ 面积，都是在投影图（上图 e）上量化的，而不是在 3D 空间上。</strong></p>
</blockquote>
<h3 id="数据标注问题"><a href="#数据标注问题" class="headerlink" title="数据标注问题"></a>数据标注问题</h3><blockquote>
<p>对于医生而言，在 OCT 或 OCTA 的 3D 数据上直接进行标注是困难的，相反在 2D 的投影图上标注则是相对简单和高效的。</p>
</blockquote>
<h3 id="已有深度学习方法的的局限性"><a href="#已有深度学习方法的的局限性" class="headerlink" title="已有深度学习方法的的局限性"></a>已有深度学习方法的的局限性</h3><p><img src="https://s2.loli.net/2022/08/08/DmW7CRPkyZ32vtU.png"></p>
<blockquote>
<p><strong>主流端到端方法</strong>：<br>（1）2D to category.<br>（2）2D to 2D semantic segmentation.<br>（3）3D to 3D semantic segmentation.<br>对于（3）而言，应用到 OCT 和 OCTA 图像上是几乎不可能的：<br>“Alternatively, they need 3D pixel-to-pixel labels, which are labor-intensive and difficult to be obtained.” <strong>或者，他们需要 3D 像素到像素的标签，这是劳动密集型且难以获得的。</strong></p>
</blockquote>
<h2 id="Image-Projection-Network-IPN"><a href="#Image-Projection-Network-IPN" class="headerlink" title="Image Projection Network (IPN)"></a>Image Projection Network (IPN)</h2><h3 id="2D-to-1D-IPN"><a href="#2D-to-1D-IPN" class="headerlink" title="2D-to-1D IPN"></a>2D-to-1D IPN</h3><blockquote>
<p><strong>（1）构造方式：</strong><br>“We use the framework of the classical VGG model for reference, remove all the full connection layers, and change the original pooling layer to the unidirectional pooling layer.” <strong>我们借鉴经典VGG模型的框架，去掉所有的全连接层，将原来的池化层改为单向池化层（下图右）。</strong><br><strong>（2）实现方式：</strong><br>将 <code>3×400×640</code> 的横截面图输入上述构造的 <code>IPN</code> 中，输出得到一维的尺寸为 <code>1×400×1</code> 的向量；通过将每个病例的 <code>400</code> 张横截面图像输入网络得到的输出向量拼接，即可得到 <code>1×400×400</code> 的预测图像。<br><strong>（3）局限性：</strong><br>最终的分割结果是通过拼接得到的，由于包含很多锯齿状的边缘，空间连续性较差。</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/08/08/AElenYcpoRbU8gj.png"></p>
<h3 id="3D-to-2D-IPN"><a href="#3D-to-2D-IPN" class="headerlink" title="3D-to-2D IPN"></a>3D-to-2D IPN</h3><blockquote>
<p>“IPN can summarize the effective features in 3D data along the projection direction and output the segmentation results on a 2D plane, to realize the semantic segmentation from 3D to 2D.” <strong>IPN 可以沿投影方向总结 3D 数据中的有效特征并在 2D 平面上输出分割结果，实现从 3D 到 2D 的语义分割。</strong></p>
</blockquote>
<p><img src="https://s2.loli.net/2022/08/08/jJFpZ8Wo1TECk3P.png"></p>
<blockquote>
<p><strong>与 2D-to-1D IPN 的差异</strong>：使用 <strong>3D 卷积</strong> 而不是 2D 卷积，并且<strong>单向池化从 2D 扩展到 3D</strong>，但仍然只作用在投影方向。 通过这种变化，IPN 可以输入 3 维图像并输出 2 维截面图。以下介绍 3D-to-2D IPN 的关键组成部分。</p>
</blockquote>
<h4 id="投影学习模块"><a href="#投影学习模块" class="headerlink" title="投影学习模块"></a>投影学习模块</h4><blockquote>
<p><strong>Projection Learning Module, PLM</strong><br>（1）组成部分：三个 卷积核尺寸为 <code>(3×3×3)</code> 的 3D 卷积层和一个单向池化层。<br>（2）单个 <code>PLM</code> 的输入输出尺寸变化：$[H \times L \times W] \rightarrow [\frac{H}{k} \times L \times W]$，其中 <code>k</code> 为单向池化层的 <code>pooling size</code>。</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/08/08/A1FIjEwidgaOc8L.png"></p>
<h4 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h4><table>
    <tr>
        <td>Layer</td><td>Channel Number</td><td>PLM Parameter</td><td>Output Size</td>
   </tr>
    <tr>
          <td>Input</td><td>2</td><td>-</td><td>640×100×100</td>
    </tr>
    <tr>
        <td>PLM1</td><td>32</td><td>5</td><td>128×100×100</td>
    </tr>
    <tr>
        <td>PLM2</td><td>64</td><td>4</td><td>32×100×100</td>
    </tr>
    <tr>
        <td>PLM3</td><td>128</td><td>4</td><td>8×100×100</td>
    </tr>
    <tr>
        <td>PLM4</td><td>256</td><td>4</td><td>2×100×100</td>
    </tr>
    <tr>
        <td>PLM5</td><td>512</td><td>2</td><td>1×100×100</td>
    </tr>
    <tr>
        <td>Conv6</td><td>256</td><td>-</td><td>1×100×100</td>
    </tr>
    <tr>
        <td>Conv7</td><td>128</td><td>-</td><td>1×100×100</td>
    </tr>
    <tr>
        <td>Conv8</td><td>2</td><td>-</td><td>1×100×100</td>
    </tr>
    <tr>
        <td>Softmax</td><td>2</td><td>-</td><td>1×100×100</td>
    </tr>
</table>

<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><blockquote>
<p>以下实现时，为了适应后面 IPN V2 论文中的输入，做了一些改动：<br>（1）输入 Patch 大小为 640×100×100；<br>（2）减少一个 pooling size &#x3D; 4 的 PLM 层，以适应输出；<br>（3）减少最后的卷积层至 1 层；<br>（4）将 <code>Softmax</code> 替换成了 <code>Sigmoid</code>，训练过程中的损失函数使用 <code>BCELoss()</code>，而非原文中提到的 <code>CELoss()</code>，本质是一样的。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">IPN</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels=<span class="hljs-number">2</span>, channels=<span class="hljs-number">32</span>, n_classes=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>(IPN, self).__init__()<br>        self.in_channels = in_channels<br>        self.channels=channels<br>        self.n_classes = n_classes<br>        self.<span class="hljs-built_in">input</span> = InConv3d(in_channels, channels)<br>        self.PLM1 = PLM(<span class="hljs-number">5</span>, channels)<br>        self.PLM2 = PLM(<span class="hljs-number">4</span>, channels*<span class="hljs-number">2</span>)<br>        self.PLM3 = PLM(<span class="hljs-number">4</span>, channels*<span class="hljs-number">4</span>)<br>        self.PLM4 = PLM(<span class="hljs-number">2</span>, channels*<span class="hljs-number">8</span>) <br>        self.output = OutConv2d(channels*<span class="hljs-number">16</span>, n_classes)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.<span class="hljs-built_in">input</span>(x)<br>        x = self.PLM1(x)<br>        x = self.PLM2(x)<br>        x = self.PLM3(x)<br>        feature = self.PLM4(x)<br>        feature = torch.squeeze(feature, <span class="hljs-number">2</span>)<br>        logits = self.output(feature)<br>        <span class="hljs-keyword">return</span> torch.sigmoid(logits), feature<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PLM</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, poolingsize, channels</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.plm = nn.Sequential(<br>            nn.MaxPool3d(kernel_size=[poolingsize, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]),<br>            nn.Conv3d(channels, channels, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv3d(channels, channels*<span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.plm(x)<br></code></pre></td></tr></table></figure>

<h3 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h3><h4 id="RV-Segmentation"><a href="#RV-Segmentation" class="headerlink" title="RV Segmentation"></a>RV Segmentation</h4><blockquote>
<p><strong>输入数据：</strong>3D 的 OCT 和 OCTA Volume，原始数据大小为 640px × 400px × 400px；<br><strong>输入大小：</strong>640px × 100px × 100px 的采样数据；<br><strong>采样方式：</strong>由于投影图中血管分布均匀，因此采用 <strong>随机采样</strong>。</p>
</blockquote>
<h4 id="FAZ-Segmentation"><a href="#FAZ-Segmentation" class="headerlink" title="FAZ Segmentation"></a>FAZ Segmentation</h4><blockquote>
<p><strong>输入数据：</strong>除了 3D 的 OCT 和 OCTA Volume外，还考虑到 FAZ 位于图像的中心区域，添加了下图所示的距离图（distance map）作为第三通道；<br><strong>输入大小：</strong>640px × 100px × 100px 的采样数据；<br><strong>采样方式：</strong>由于投影图中 FAZ 仅占一小部分，导致 FAZ 的分割中存在正负样本的不平衡问题，为了增加正样本的比例，采用以投影中心为中心的 <strong>正态分布采样</strong>，以增加中心位置被选为训练数据的概率。</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/08/08/pV5X7jR4guvokdy.png"></p>
<h4 id="参数配置"><a href="#参数配置" class="headerlink" title="参数配置"></a>参数配置</h4><table>
    <tr>
        <td>Optimizer</td><td>Adam Stochastic Optimization</td>
    </tr>
    <tr>
        <td>GPU</td><td>1 NVIDIA GeForce GTX 1080Ti</td>
    </tr>
      <tr>
        <td>Loss Function</td><td>Cross-entropy</td>
    </tr>
    <tr>
        <td>Batch Size</td><td>3</td>
    </tr>
    <tr>
        <td>Max Iteration Number</td><td>20000</td>
    </tr>
    <tr>
        <td>Initial Learning Rate</td><td>10^(-4)</td>
    </tr>
</table>

<h3 id="对比实验"><a href="#对比实验" class="headerlink" title="对比实验"></a>对比实验</h3><h4 id="3D-to-2D-IPN-vs-2D-to-1D-IPN"><a href="#3D-to-2D-IPN-vs-2D-to-1D-IPN" class="headerlink" title="3D-to-2D IPN vs. 2D-to-1D IPN"></a>3D-to-2D IPN vs. 2D-to-1D IPN</h4><blockquote>
<p>2D-to-1D IPN 在训练过程中缺少空间信息，导致预测结果中心存在明显的锯齿状。</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/08/08/cJDWQtAq7dvi9lG.png"><br><img src="https://s2.loli.net/2022/08/08/4BIcpjNluJC7oQM.png" alt="FAZ分割结果使用 2D-to-1D IPN（左）和 3D-to-2D IPN（右）。红线代表真值图，黄线和绿线分别代表 2D-to-1D IPN 和 3D-to-2D IPN 的结果。"></p>
<h4 id="Multi-Channel-vs-Single-Channel"><a href="#Multi-Channel-vs-Single-Channel" class="headerlink" title="Multi-Channel vs. Single-Channel"></a>Multi-Channel vs. Single-Channel</h4><blockquote>
<p>（1）OCTA &gt; OCT；<br>（2）多模态数据 &gt; 单模态数据；<br>（3）<strong>Distance Map 的引入</strong> 增大了中心区域的权重，使得 FAZ 的分割结果上涨了 5 个百分点。（”Distance map plays an important role, which is related to the location specificity of FAZ. Without the distance map, the network mistakenly assumes that the areas with weak blood flow signals belong to FAZ, such as the weakening of local signals due to turbid refractive media and non-perfusion zone.” 距离图起着重要的作用，这与 FAZ 的位置特异性有关。 在没有距离图的情况下，网络错误地认为血流信号较弱的区域属于FAZ，例如由于屈光介质混浊和非灌注区导致局部信号减弱。）</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/08/08/TnCejam5WVsdq4f.png"><br><img src="https://s2.loli.net/2022/08/08/efEOp29adl4HviM.png" alt="FAZ 分割结果的三个示例。 (a)-(c) 中的黄色区域代表真值图。 (d-f) 中的彩色线表示不同输入的 IPN 的结果：OCT（红线）、OCTA（绿线）、OCT+OCTA（蓝线）、OCT+OCTA+Distance map（黄线）"></p>
<h4 id="IPN-vs-Others"><a href="#IPN-vs-Others" class="headerlink" title="IPN vs. Others"></a>IPN vs. Others</h4><blockquote>
<p>（1）IPN 优于任何 2D 方法<br>（2）IPN 架构优于 U-Net 架构（max-pooling 和 skip-connection）</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/08/08/ifJ4FwtGCPsylvc.png" alt="PRO + * 表示使用投影图进行分割的 2D 方法"></p>
<h2 id="IPN-V2"><a href="#IPN-V2" class="headerlink" title="IPN V2"></a>IPN V2</h2><h3 id="Plane-Perceptron"><a href="#Plane-Perceptron" class="headerlink" title="Plane Perceptron"></a>Plane Perceptron</h3><blockquote>
<p><strong>设计 V2 版本的出发点：</strong>IPN 的主要功能是将 3D 体积信息汇总成 2D 平面。 由于缺乏水平方向的下采样，它缺乏二维平面中的高级语义信息。<br><strong>解决方法：</strong>使用 U-Net 作为平面感知器（Plane Perceptron），并将其连接在 IPN 后面。 此外，将 IPN 输出的 2D 特征和第一个 PLM 输出的 3D 特征连接起来，以防止梯度消失并加快收敛进程。</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/08/08/YMBeCLrU6fWsO74.png"></p>
<h3 id="Global-Retraining"><a href="#Global-Retraining" class="headerlink" title="Global Retraining"></a>Global Retraining</h3><blockquote>
<p>简单来说，就是<strong>把 IPN V2 的预测结果（Patch）拼接到一起，然后再用 U-Net 训练一遍</strong>。 并且，在图像拼接的时候采用 <strong>重叠</strong> 的方法以减少拼接过程带来的“棋盘效应”。</p>
</blockquote>
<h3 id="训练细节-1"><a href="#训练细节-1" class="headerlink" title="训练细节"></a>训练细节</h3><blockquote>
<p><strong>IPN V2 的训练细节较 IPN 而言有较大变化：</strong><br>（1）<strong>数据集扩充</strong>：从 316 例 6mm×6mm，扩充至 300 例 6mm×6mm 和 200 例 3mm×3mm 的 OCT 和 OCTA Volume；原始数据大小分别为 640px × 400px × 400px 和 640px × 304px × 304px；<br>（2）<strong>输入大小：</strong>分别为 <strong>160px</strong> × 100px × 100px 和 <strong>160px</strong> × 76px × 76px 的采样数据；<br>（3）<strong>参数调整：</strong>Maximum iteration number - 30000，Batch size - 1;<br>（4）<strong>Global Training 参数：</strong>Maximum iteration number - 5000，Batch size - 2。</p>
</blockquote>
<h3 id="对比实验-1"><a href="#对比实验-1" class="headerlink" title="对比实验"></a>对比实验</h3><h4 id="RV-Segmentation-1"><a href="#RV-Segmentation-1" class="headerlink" title="RV Segmentation"></a>RV Segmentation</h4><p><img src="https://s2.loli.net/2022/08/08/7PhX3A1HYQ6Oq52.png"></p>
<h4 id="FAZ-Segmentation-1"><a href="#FAZ-Segmentation-1" class="headerlink" title="FAZ Segmentation"></a>FAZ Segmentation</h4><p><img src="https://s2.loli.net/2022/08/08/dBsiqL3zKOmQgVT.png"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">SvyJ</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/08/08/034-IPN_Series/">http://example.com/2022/08/08/034-IPN_Series/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">“干杯( ﾟ-ﾟ)っロ”</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/">网络模型</a><a class="post-meta__tags" href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/">图像分割</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2022/08/08/jJFpZ8Wo1TECk3P.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/08/10/033-SwinTransformer/" title="Swin Transformer 论文阅读笔记"><img class="cover" src="https://s2.loli.net/2022/08/08/Kn2H1Jwq8ucS4lF.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Swin Transformer 论文阅读笔记</div></div></a></div><div class="next-post pull-right"><a href="/2022/07/05/021-VesselSegmentation/" title="医学图像中的血管分割"><img class="cover" src="https://s2.loli.net/2022/07/05/IrpVOv3lQtRTCPW.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">医学图像中的血管分割</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/07/05/007-DL_Models_Segmentation/" title="经典分割模型的Pytorch实现"><img class="cover" src="https://s2.loli.net/2022/06/30/mh1gcH8wJx9QMCs.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-05</div><div class="title">经典分割模型的Pytorch实现</div></div></a></div><div><a href="/2022/07/01/010-Semantic_Segementation/" title="语义分割综述"><img class="cover" src="https://i.loli.net/2021/07/05/z3mAyiTIeYhFDQO.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-01</div><div class="title">语义分割综述</div></div></a></div><div><a href="/2022/07/05/021-VesselSegmentation/" title="医学图像中的血管分割"><img class="cover" src="https://s2.loli.net/2022/07/05/IrpVOv3lQtRTCPW.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-05</div><div class="title">医学图像中的血管分割</div></div></a></div><div><a href="/2022/07/05/022-Transformers/" title="Transformer系列的简单整理（挖坑）"><img class="cover" src="https://s2.loli.net/2021/12/22/raDjVhH3egsF9fx.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-05</div><div class="title">Transformer系列的简单整理（挖坑）</div></div></a></div><div><a href="/2022/07/05/002-LeNet_Mnist/" title="深度学习算法中的Hello-World：用LeNet模型实现手写数字识别"><img class="cover" src="https://i.loli.net/2021/07/05/uVxbZ7TaRqkijHf.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-05</div><div class="title">深度学习算法中的Hello-World：用LeNet模型实现手写数字识别</div></div></a></div><div><a href="/2022/06/30/006-DL_Papers/" title="CV Papers"><img class="cover" src="https://s2.loli.net/2022/06/30/RaKgipTrNYwZqPv.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-30</div><div class="title">CV Papers</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E6%8A%95%E5%BD%B1%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%9D%A5%E6%BA%90"><span class="toc-number">1.</span> <span class="toc-text">图像投影网络的设计来源</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9C%BC%E7%A7%91%E4%B8%B4%E5%BA%8A"><span class="toc-number">1.1.</span> <span class="toc-text">眼科临床</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%8A%E7%96%97%E6%8C%87%E6%A0%87"><span class="toc-number">1.2.</span> <span class="toc-text">诊疗指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%A0%87%E6%B3%A8%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.</span> <span class="toc-text">数据标注问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%B2%E6%9C%89%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">1.4.</span> <span class="toc-text">已有深度学习方法的的局限性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Image-Projection-Network-IPN"><span class="toc-number">2.</span> <span class="toc-text">Image Projection Network (IPN)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2D-to-1D-IPN"><span class="toc-number">2.1.</span> <span class="toc-text">2D-to-1D IPN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3D-to-2D-IPN"><span class="toc-number">2.2.</span> <span class="toc-text">3D-to-2D IPN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8A%95%E5%BD%B1%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9D%97"><span class="toc-number">2.2.1.</span> <span class="toc-text">投影学习模块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84"><span class="toc-number">2.2.2.</span> <span class="toc-text">模型架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.2.3.</span> <span class="toc-text">代码实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82"><span class="toc-number">2.3.</span> <span class="toc-text">训练细节</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RV-Segmentation"><span class="toc-number">2.3.1.</span> <span class="toc-text">RV Segmentation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#FAZ-Segmentation"><span class="toc-number">2.3.2.</span> <span class="toc-text">FAZ Segmentation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-number">2.3.3.</span> <span class="toc-text">参数配置</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E5%AE%9E%E9%AA%8C"><span class="toc-number">2.4.</span> <span class="toc-text">对比实验</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3D-to-2D-IPN-vs-2D-to-1D-IPN"><span class="toc-number">2.4.1.</span> <span class="toc-text">3D-to-2D IPN vs. 2D-to-1D IPN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Multi-Channel-vs-Single-Channel"><span class="toc-number">2.4.2.</span> <span class="toc-text">Multi-Channel vs. Single-Channel</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#IPN-vs-Others"><span class="toc-number">2.4.3.</span> <span class="toc-text">IPN vs. Others</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#IPN-V2"><span class="toc-number">3.</span> <span class="toc-text">IPN V2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Plane-Perceptron"><span class="toc-number">3.1.</span> <span class="toc-text">Plane Perceptron</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Global-Retraining"><span class="toc-number">3.2.</span> <span class="toc-text">Global Retraining</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82-1"><span class="toc-number">3.3.</span> <span class="toc-text">训练细节</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E5%AE%9E%E9%AA%8C-1"><span class="toc-number">3.4.</span> <span class="toc-text">对比实验</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RV-Segmentation-1"><span class="toc-number">3.4.1.</span> <span class="toc-text">RV Segmentation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#FAZ-Segmentation-1"><span class="toc-number">3.4.2.</span> <span class="toc-text">FAZ Segmentation</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2022/08/08/jJFpZ8Wo1TECk3P.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By SvyJ</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hello, Stranger~</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'e5bWQMoOycxPCdtTvxkPGJ0d-gzGzoHsz',
      appKey: 'peE7twywLp5HcdBx6gmKQYUH',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>